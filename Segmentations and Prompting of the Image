import torch
from PIL import Image
import clip
from segment_anything import SamAutomaticMaskGenerator, sam_model_registry
import cv2
import numpy as np
import argparse
import os

def load_clip_model(device):
    """ Load the CLIP model """
    clip_model, preprocess = clip.load("ViT-B/32", device=device)
    return clip_model, preprocess

def generate_masks(sam, image_array):
    """ Generate segmentation masks using SAM """
    mask_generator = SamAutomaticMaskGenerator(sam)
    masks = mask_generator.generate(image_array)
    return masks

def load_sam_model(checkpoint_path):
    """ Load the SAM model """
    sam = sam_model_registry["vit_h"](checkpoint=checkpoint_path)
    return sam

def main(image_path, object_class, output_path):
    # Validate image path
    if not os.path.isfile(image_path):
        print(f"Error: Image file '{image_path}' not found.")
        return
    
    # Validate SAM checkpoint path
    sam_checkpoint = "/kaggle/working/sam_vit_h_4b8939.pth"
    if not os.path.isfile(sam_checkpoint):
        print(f"Error: SAM checkpoint file '{sam_checkpoint}' not found.")
        print("Please download the checkpoint from: https://github.com/facebookresearch/segment-anything")
        return

    # Load CLIP model and SAM model
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    clip_model, preprocess = load_clip_model(device)
    sam = load_sam_model(sam_checkpoint)

    # Load and preprocess the image
    image = Image.open(image_path).convert("RGB")
    image_input = preprocess(image).unsqueeze(0).to(device)
    text_input = clip.tokenize([object_class]).to(device)

    # Compute image and text features
    with torch.no_grad():
        image_features = clip_model.encode_image(image_input)
        text_features = clip_model.encode_text(text_input)

    # Calculate cosine similarity between text and image
    similarity = torch.cosine_similarity(image_features, text_features)
    print(f"Similarity score for '{object_class}': {similarity.item()}")

    # Generate segmentation masks using SAM
    image_array = np.array(image)
    masks = generate_masks(sam, image_array)

    # Initialize a blank mask
    final_mask = np.zeros(image_array.shape[:2], dtype=np.uint8)

    # Apply masks where objects are found
    for mask in masks:
        final_mask[mask['segmentation']] = 255
    
    # Create a red mask on the original image
    red_mask = np.zeros_like(image_array)
    red_mask[final_mask == 255] = [255, 0, 0]  # Red color

    # Overlay the mask on the original image
    overlay_image = cv2.addWeighted(image_array, 1, red_mask, 0.5, 0)

    # Save the output image
    output_image = Image.fromarray(overlay_image)
    output_image.save(output_path)
    print(f"Output saved to '{output_path}'.")
    
    
#main('/kaggle/input/more-animals-images/cat-and-dog-sitting-together-against-white-background-E7G6TY.jpg', 'cat', 'output_image1.png')
